{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the GPT Client\n",
    "from openai_connection_helper import get_gpt_client, get_gpt_response_with_system_and_user_message\n",
    "\n",
    "gpt_client = get_gpt_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a message to GPT with the direct prompt\n",
    "from generate_score_prompt import direct_prompt_full_question_setup, format_student_response_full_question\n",
    "\n",
    "def prompt_gpt_with_direct_full_question(student_response_part_a, student_response_part_b, with_explanation=False, with_examples=False):\n",
    "    system_message = direct_prompt_full_question_setup(with_explanation=with_explanation, with_examples=with_examples)\n",
    "    print(system_message)\n",
    "    user_message = format_student_response_full_question(student_response_part_a, student_response_part_b)\n",
    "    print(user_message)\n",
    "\n",
    "    return get_gpt_response_with_system_and_user_message(system_message, user_message, gpt_client=gpt_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "Question:Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "    \n",
      "Part A: What does Mark need to do next to complete the problem?\n",
      "    \n",
      "Part B: What is the answer to 143 - 48?\n",
      "\n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect response\n",
      "Give the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}\n",
      "Student Response:\n",
      "    \n",
      "Part A: Subtract five from 100\n",
      "    \n",
      "Part B: 95\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": Incorrect,\\n    \"Part B\": Incorrect,\\n    \"Overall\": Incorrect\\n}\\n```'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_student_response_part_a = \"Subtract five from 100\"\n",
    "correct_student_response_part_b = \"95\"\n",
    "prompt_gpt_with_direct_full_question(correct_student_response_part_a, correct_student_response_part_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "Question:Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "    \n",
      "Part A: What does Mark need to do next to complete the problem?\n",
      "    \n",
      "Part B: What is the answer to 143 - 48?\n",
      "\n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect response\n",
      "Give the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}Consider the following correctly scored examples when scoring student responsesStudent Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 105 Score: Incorrect\n",
      "\n",
      "Student Response:\n",
      "    \n",
      "Part A: Subtract five from 100\n",
      "    \n",
      "Part B: 95\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_direct_full_question(correct_student_response_part_a, correct_student_response_part_b, with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "Question:Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "    \n",
      "Part A: What does Mark need to do next to complete the problem?\n",
      "    \n",
      "Part B: What is the answer to 143 - 48?\n",
      "The following explains the correct and incorrect values for each part.\n",
      "Part A: The following samples are scored as correct because they indicate that 5 should be subtracted from 100 for part (a).\n",
      "Part B: The following samples are scored as correct because they indicate that the difference is 95 for part (b).\n",
      "\n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect response\n",
      "Give the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}\n",
      "Student Response:\n",
      "    \n",
      "Part A: Subtract five from 100\n",
      "    \n",
      "Part B: 95\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_direct_full_question(correct_student_response_part_a, correct_student_response_part_b, with_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "Question:Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "    \n",
      "Part A: What does Mark need to do next to complete the problem?\n",
      "    \n",
      "Part B: What is the answer to 143 - 48?\n",
      "The following explains the correct and incorrect values for each part.\n",
      "Part A: The following samples are scored as correct because they indicate that 5 should be subtracted from 100 for part (a).\n",
      "Part B: The following samples are scored as correct because they indicate that the difference is 95 for part (b).\n",
      "\n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect response\n",
      "Give the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}Consider the following correctly scored examples when scoring student responsesStudent Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 105 Score: Incorrect\n",
      "\n",
      "Student Response:\n",
      "    \n",
      "Part A: Subtract five from 100\n",
      "    \n",
      "Part B: 95\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_direct_full_question(correct_student_response_part_a, correct_student_response_part_b, with_explanation=True, with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "Question:Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "    \n",
      "Part A: What does Mark need to do next to complete the problem?\n",
      "    \n",
      "Part B: What is the answer to 143 - 48?\n",
      "The following explains the correct and incorrect values for each part.\n",
      "Part A: The following samples are scored as correct because they indicate that 5 should be subtracted from 100 for part (a).\n",
      "Part B: The following samples are scored as correct because they indicate that the difference is 95 for part (b).\n",
      "\n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect response\n",
      "Give the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}Consider the following correctly scored examples when scoring student responsesStudent Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: mark needs to subtract 5 from 100. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: 100 - 5 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: subtract 5 more \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from 100 \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 95 Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: ninety five Score: Correct\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 100 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 97 Score: Partial 1\n",
      "Student Response: Part A: Subtract 5 from the result found in step 1. \n",
      " Part B: 105 Score: Partial 1\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 143 - 48 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: 5 - 100 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: + 5 \n",
      " Part B: 105 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 95 Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: ninety five Score: Partial 2\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 100 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 97 Score: Incorrect\n",
      "Student Response: Part A: Student Response: 100 - 3 \n",
      " Part B: 105 Score: Incorrect\n",
      "\n",
      "Student Response:\n",
      "    \n",
      "Part A: Subtract five from 100\n",
      "    \n",
      "Part B: 95\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_student_response_part_a = \"Subtract five from 100\"\n",
    "correct_student_response_part_b = \"95\"\n",
    "prompt_gpt_with_direct_full_question(correct_student_response_part_a, correct_student_response_part_b, with_examples=True, with_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a message to GPT with sub question prompts\n",
    "from generate_score_prompt import create_sub_question_prompt_part_a, create_sub_question_prompt_part_b, format_student_response_sub_question\n",
    "\n",
    "def prompt_gpt_with_part_a_question(student_response_part_a, with_examples=False, with_explanation=False):\n",
    "    system_message_part_a = create_sub_question_prompt_part_a(with_examples=with_examples, with_explanation=with_explanation)\n",
    "    print(system_message_part_a)\n",
    "    user_message_part_a = format_student_response_sub_question(student_response_part_a)\n",
    "    print(user_message_part_a)\n",
    "    return get_gpt_response_with_system_and_user_message(system_message_part_a, user_message_part_a, gpt_client=gpt_client)\n",
    "\n",
    "def prompt_gpt_with_part_b_question(student_response_part_b, with_examples=False, with_explanation=False):\n",
    "    system_message_part_b = create_sub_question_prompt_part_b(with_examples=with_examples, with_explanation=with_explanation)\n",
    "    print(system_message_part_b)\n",
    "    user_message_part_b = format_student_response_sub_question(student_response_part_b)\n",
    "    print(user_message_part_b)\n",
    "    return get_gpt_response_with_system_and_user_message(system_message_part_b, user_message_part_b, gpt_client=gpt_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "\n",
      "Student Response: Subtract five from 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Correct. \\n\\nMark initially subtracts 43 from 143, which leaves him with 100. To complete the problem, he needs to subtract the remaining 5 (since 48 - 43 = 5) from 100.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_a_question(correct_student_response_part_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "Consider the following correctly scored examples in your response: \n",
      "Student Response: mark needs to subtract 5 from 100.: Score: Correct\n",
      "Student Response: 100 - 5: Score: Correct\n",
      "Student Response: subtract 5 more: Score: Correct\n",
      "Student Response: Subtract 5 from 100: Score: Correct\n",
      "Student Response: Subtract 5 from the result found in step 1.: Score: Correct\n",
      "Student Response: 143 - 48: Score: Inorrect\n",
      "Student Response: 5 - 100: Score: Inorrect\n",
      "Student Response: + 5: Score: Inorrect\n",
      "Student Response: Student Response: 100 - 3: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: Subtract five from 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Score: Correct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_a_question(correct_student_response_part_a, with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "Consider the following correctly scored examples in your response: \n",
      "The following samples are scored as correct because they indicate that 5 should be subtracted from 100 for part (a).\n",
      "Student Response: mark needs to subtract 5 from 100.: Score: Correct\n",
      "Student Response: 100 - 5: Score: Correct\n",
      "Student Response: subtract 5 more: Score: Correct\n",
      "Student Response: Subtract 5 from 100: Score: Correct\n",
      "Student Response: Subtract 5 from the result found in step 1.: Score: Correct\n",
      "The following samples are incorrect because they do not indicate that 5 should be subtracted from 100.\n",
      "Student Response: 143 - 48: Score: Inorrect\n",
      "Student Response: 5 - 100: Score: Inorrect\n",
      "Student Response: + 5: Score: Inorrect\n",
      "Student Response: Student Response: 100 - 3: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: Subtract five from 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Score: Correct'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_a_question(correct_student_response_part_a, with_examples=True, with_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "Consider the following correctly scored examples in your response: \n",
      "The following samples are scored as correct because they indicate that the difference is 95 for part (b).\n",
      "Student Response: 95: Score: Correct\n",
      "Student Response: ninety five: Score: Correct\n",
      "The following samples are incorrect because the difference is not equal to 95.\n",
      "Student Response: 100: Score: Inorrect\n",
      "Student Response: 97: Score: Inorrect\n",
      "Student Response: 105: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Score: Correct'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_b_question(correct_student_response_part_b, with_examples=True, with_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "Consider the following correctly scored examples in your response: \n",
      "Student Response: 95: Score: Correct\n",
      "Student Response: ninety five: Score: Correct\n",
      "Student Response: 100: Score: Inorrect\n",
      "Student Response: 97: Score: Inorrect\n",
      "Student Response: 105: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Score: Correct'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_b_question(correct_student_response_part_b, with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "\n",
      "Student Response: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Correct'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt_with_part_b_question(correct_student_response_part_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined score\n",
    "from generate_score_prompt import create_combined_score_prompt, format_overall_score_user_message\n",
    "\n",
    "def prompt_gpt_for_overall_score(part_a_score, part_b_score):\n",
    "    system_message = create_combined_score_prompt()\n",
    "    print(system_message)\n",
    "    user_message = format_overall_score_user_message(part_a_score, part_b_score)\n",
    "    print(user_message)\n",
    "    \n",
    "    return get_gpt_response_with_system_and_user_message(system_message, user_message, gpt_client=gpt_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_subparts_then_overall_score(student_response_part_a, student_response_part_b, with_explanation=False, with_examples=False):\n",
    "    part_a_score = prompt_gpt_with_part_a_question(student_response_part_a, with_explanation=with_explanation, with_examples=with_examples)\n",
    "    \n",
    "    part_b_score = prompt_gpt_with_part_b_question(student_response_part_b, with_explanation=with_explanation, with_examples=with_examples)\n",
    "\n",
    "    combined_score = prompt_gpt_for_overall_score(part_a_score, part_b_score)\n",
    "\n",
    "    return dict({'GPTScorePartA': part_a_score,\n",
    "                 'GPTScorePartB': part_b_score,\n",
    "                 'GPTCombinedScore': combined_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "\n",
      "Student Response: Subtract five from 100\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "\n",
      "Student Response: 95\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.You are grading at two part question and the subparts have already been graded.  Give an overall score based on the following rubric. \n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect responseGive the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}\n",
      "Component Scores:\n",
      "\n",
      "        Part A: Correct. \n",
      "\n",
      "Mark initially subtracts 43 from 143, which leaves him with 100. To complete the problem, he needs to subtract the remaining 5 (since 48 - 43 = 5) from 100.\n",
      "\n",
      "        Part B: Correct\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPTScorePartA': 'Correct. \\n\\nMark initially subtracts 43 from 143, which leaves him with 100. To complete the problem, he needs to subtract the remaining 5 (since 48 - 43 = 5) from 100.',\n",
       " 'GPTScorePartB': 'Correct',\n",
       " 'GPTCombinedScore': '```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_subparts_then_overall_score(correct_student_response_part_a, correct_student_response_part_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "Consider the following correctly scored examples in your response: \n",
      "Student Response: mark needs to subtract 5 from 100.: Score: Correct\n",
      "Student Response: 100 - 5: Score: Correct\n",
      "Student Response: subtract 5 more: Score: Correct\n",
      "Student Response: Subtract 5 from 100: Score: Correct\n",
      "Student Response: Subtract 5 from the result found in step 1.: Score: Correct\n",
      "Student Response: 143 - 48: Score: Inorrect\n",
      "Student Response: 5 - 100: Score: Inorrect\n",
      "Student Response: + 5: Score: Inorrect\n",
      "Student Response: Student Response: 100 - 3: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: Subtract five from 100\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "Consider the following correctly scored examples in your response: \n",
      "Student Response: 95: Score: Correct\n",
      "Student Response: ninety five: Score: Correct\n",
      "Student Response: 100: Score: Inorrect\n",
      "Student Response: 97: Score: Inorrect\n",
      "Student Response: 105: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: 95\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.You are grading at two part question and the subparts have already been graded.  Give an overall score based on the following rubric. \n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect responseGive the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}\n",
      "Component Scores:\n",
      "\n",
      "        Part A: Score: Correct\n",
      "\n",
      "        Part B: Score: Correct\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPTScorePartA': 'Score: Correct',\n",
       " 'GPTScorePartB': 'Score: Correct',\n",
       " 'GPTCombinedScore': '```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_subparts_then_overall_score(correct_student_response_part_a, correct_student_response_part_b, with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What does Mark need to do next to complete the problem\n",
      "Consider the following correctly scored examples in your response: \n",
      "The following samples are scored as correct because they indicate that 5 should be subtracted from 100 for part (a).\n",
      "Student Response: mark needs to subtract 5 from 100.: Score: Correct\n",
      "Student Response: 100 - 5: Score: Correct\n",
      "Student Response: subtract 5 more: Score: Correct\n",
      "Student Response: Subtract 5 from 100: Score: Correct\n",
      "Student Response: Subtract 5 from the result found in step 1.: Score: Correct\n",
      "The following samples are incorrect because they do not indicate that 5 should be subtracted from 100.\n",
      "Student Response: 143 - 48: Score: Inorrect\n",
      "Student Response: 5 - 100: Score: Inorrect\n",
      "Student Response: + 5: Score: Inorrect\n",
      "Student Response: Student Response: 100 - 3: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: Subtract five from 100\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.\n",
      "The question setup is: Mark needs to solve the problem 143-48.  He will solve the problem in two steps.  First, Mark subtracts 43 from 143.\n",
      "Grade the student response to the following question as being Incorrect or Correct.\n",
      "Question: What is the answer to 143 - 48?\n",
      "Consider the following correctly scored examples in your response: \n",
      "The following samples are scored as correct because they indicate that the difference is 95 for part (b).\n",
      "Student Response: 95: Score: Correct\n",
      "Student Response: ninety five: Score: Correct\n",
      "The following samples are incorrect because the difference is not equal to 95.\n",
      "Student Response: 100: Score: Inorrect\n",
      "Student Response: 97: Score: Inorrect\n",
      "Student Response: 105: Score: Inorrect\n",
      "\n",
      "\n",
      "Student Response: 95\n",
      "You are a national mathematics assessment scoring assistant.  You must score student responses given a scoring rubric and output the response in your rubric.You are grading at two part question and the subparts have already been graded.  Give an overall score based on the following rubric. \n",
      "Scoring Rubric:\n",
      "    \n",
      "Correct: Both parts correct\n",
      "    \n",
      "Partial 1: Part A correct only\n",
      "    \n",
      "Partial 2: Part B correct only\n",
      "    \n",
      "Incorrect: Incorrect responseGive the response in the format of a python dictionary like the following:\n",
      "    {\"Part A\": <Incorrect/Correct>, \"Part B\": <Incorrect/Correct>, \"Overall\": <Incorrect/Partial 1/Partial 2/Correct>}\n",
      "Component Scores:\n",
      "\n",
      "        Part A: Score: Correct\n",
      "\n",
      "        Part B: Score: Correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict = prompt_subparts_then_overall_score(correct_student_response_part_a, correct_student_response_part_b, with_examples=True, with_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "    \"Part A\": \"Correct\",\n",
      "    \"Part B\": \"Correct\",\n",
      "    \"Overall\": \"Correct\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result_dict['GPTCombinedScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "    \"Part A\": \"Correct\",\n",
      "    \"Part B\": \"Correct\",\n",
      "    \"Overall\": \"Correct\"\n",
      "}\n",
      "```\n",
      "```python\n",
      "{\n",
      "    \"Part A\": \"Correct\",\n",
      "    \"Part B\": \"Correct\",\n",
      "    \"Overall\": \"Correct\"\n",
      "}\n",
      "```\n",
      "['{']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "combined_score_string = result_dict['GPTCombinedScore']\n",
    "print(combined_score_string)\n",
    "clean_combined_score = combined_score_string.replace('\\n', '')\n",
    "print(clean_combined_score)\n",
    "res = re.findall(r\"{\", str(clean_combined_score))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\\\n hello}']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = re.findall(r\"\\{.*?\\}\", \"{\\\\n hello}\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\n{\\n    \"Part A\": \"Correct\",\\n    \"Part B\": \"Correct\",\\n    \"Overall\": \"Correct\"\\n}\\n```'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_score_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_a_key = 'partakey'\n",
    "part_b_key = 'partbkey'\n",
    "direct_prompt_key = 'direct_prompt_score'\n",
    "direct_prompt_expl_key = 'direct_prompt_with_expl_score'\n",
    "direct_prompt_examples_key = 'direct_prompt_few_shot_socre'\n",
    "cot_prompt_key = 'cot_score'\n",
    "cot_with_examples_key = 'cot_few_shot_score'\n",
    "cot_with_expl_key = 'cot_with_expl_score'\n",
    "\n",
    "# This function will return the result for all prompt variations for a dataframe\n",
    "def execute_all_prompts_for_dataframe(student_response_df, output_file):\n",
    "    # Direct Prompting variations\n",
    "    print(\"Prompting with Direct Prompt Strategy\")\n",
    "    student_response_df[direct_prompt_key] = prompt_gpt_with_direct_full_question(student_response_df[part_a_key], student_response_df[part_b_key])\n",
    "    student_response_df[direct_prompt_expl_key] = prompt_gpt_with_direct_full_question(student_response_df[part_a_key], student_response_df[part_b_key], with_explanation=True),\n",
    "    student_response_df[direct_prompt_examples_key] = prompt_gpt_with_direct_full_question(student_response_df[part_a_key], student_response_df[part_b_key], with_explanation=True, with_examples=True)\n",
    "    \n",
    "    print(\"Prompting with CoT Prompt Strategy\")\n",
    "    # Chain of Thought Prompting Variations\n",
    "    student_response_df[cot_prompt_key] = prompt_subparts_then_overall_score(student_response_df[part_a_key], student_response_df[part_b_key])\n",
    "    student_response_df[cot_with_examples_key] = prompt_subparts_then_overall_score(student_response_df[part_a_key], student_response_df[part_b_key], with_examples=True)\n",
    "    student_response_df[cot_with_expl_key] = prompt_subparts_then_overall_score(student_response_df[part_a_key], student_response_df[part_b_key], with_examples=True, with_explanation=True)\n",
    "    \n",
    "    print(\"Writing output to CSV: \" + output_file)\n",
    "    student_response_df.to_csv(output_file)\n",
    "    \n",
    "    return student_response_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# THIS IS THE MAIN FUNCTION THAT TAKES IN A CSV LOCATION AND OUTPUT FILE \n",
    "def read_csv_and_run_prompts(student_response_csv, output_predictions_csv):\n",
    "    student_response_df = pd.read_csv(student_response_csv)\n",
    "    print(\"Number of inputs: \" + str(len(student_response_df)))\n",
    "    print(\"Starting Prompt Executions\")\n",
    "\n",
    "    result_df_with_prompts = execute_all_prompts_for_dataframe(student_response_df, output_predictions_csv)\n",
    "    print(\"Number of resulting outputs:  \" + str(len(result_df_with_prompts)))\n",
    "\n",
    "    # Evaluation code should go here\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
